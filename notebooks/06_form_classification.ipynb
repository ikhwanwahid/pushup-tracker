{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06 — Form Classification: Baseline vs 3D CNN vs ST-GCN\n",
    "\n",
    "Binary form classification (correct vs incorrect) using three approaches:\n",
    "1. **Logistic Regression** baseline on per-video angle statistics\n",
    "2. **3D CNN (R3D-18)** fine-tuned on raw video frames\n",
    "3. **ST-GCN** on skeleton keypoint sequences\n",
    "\n",
    "All evaluated on the same 5-fold stratified cross-validation splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "import json\n",
    "import logging\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "from src.classification.stgcn import PushUpSTGCN\n",
    "from src.classification.video_classifier import PushUpVideoClassifier\n",
    "from src.classification.datasets import PushUpSkeletonDataset, PushUpVideoDataset\n",
    "from src.classification.train_classifier import run_kfold_cv\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(levelname)s: %(message)s\")\n",
    "\n",
    "# Load manifest\n",
    "with open(\"../data/processed/keypoints/manifest.json\") as f:\n",
    "    manifest = json.load(f)\n",
    "\n",
    "# Build video_ids and labels\n",
    "video_ids = sorted(manifest.keys())\n",
    "labels = [0 if manifest[v][\"label\"] == \"correct\" else 1 for v in video_ids]\n",
    "labels_arr = np.array(labels)\n",
    "\n",
    "print(f\"Total videos: {len(video_ids)}\")\n",
    "print(f\"  Correct: {sum(1 for l in labels if l == 0)}\")\n",
    "print(f\"  Incorrect: {sum(1 for l in labels if l == 1)}\")\n",
    "\n",
    "# Device selection\n",
    "if torch.cuda.is_available():\n",
    "    device_str = \"cuda\"\n",
    "elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "    device_str = \"mps\"\n",
    "else:\n",
    "    device_str = \"cpu\"\n",
    "print(f\"Using device: {device_str}\")\n",
    "\n",
    "# Common CV config\n",
    "RANDOM_STATE = 42\n",
    "N_SPLITS = 5\n",
    "skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Baseline — Logistic Regression\n",
    "\n",
    "Uses 16 per-video angle statistics (mean/min/max/range for elbow, back, hip, knee angles) from `feature_summary.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-computed feature summary\n",
    "feat_df = pd.read_csv(\"../data/processed/features/feature_summary.csv\")\n",
    "feat_df = feat_df.set_index(\"video_id\")\n",
    "\n",
    "# Build feature matrix with 16 features (mean/min/max/range for 4 angles)\n",
    "angle_names = [\"elbow\", \"back\", \"hip\", \"knee\"]\n",
    "stat_names = [\"mean\", \"min\", \"max\"]\n",
    "\n",
    "# Existing columns: {angle}_{stat}\n",
    "feature_cols = []\n",
    "for angle in angle_names:\n",
    "    for stat in stat_names:\n",
    "        col = f\"{angle}_{stat}\"\n",
    "        feature_cols.append(col)\n",
    "\n",
    "# Add range features\n",
    "for angle in angle_names:\n",
    "    range_col = f\"{angle}_range\"\n",
    "    feat_df[range_col] = feat_df[f\"{angle}_max\"] - feat_df[f\"{angle}_min\"]\n",
    "    feature_cols.append(range_col)\n",
    "\n",
    "# Align with video_ids order\n",
    "X_baseline = feat_df.loc[video_ids, feature_cols].values.astype(np.float32)\n",
    "y_baseline = labels_arr\n",
    "\n",
    "print(f\"Feature matrix: {X_baseline.shape}\")\n",
    "print(f\"Features: {feature_cols}\")\n",
    "\n",
    "# Cross-validated predictions using the SAME splits\n",
    "pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"lr\", LogisticRegression(max_iter=1000, random_state=RANDOM_STATE)),\n",
    "])\n",
    "\n",
    "baseline_preds = cross_val_predict(pipeline, X_baseline, y_baseline, cv=skf)\n",
    "baseline_acc = accuracy_score(y_baseline, baseline_preds)\n",
    "\n",
    "# Per-fold accuracy\n",
    "baseline_fold_accs = []\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_baseline, y_baseline)):\n",
    "    fold_acc = accuracy_score(y_baseline[val_idx], baseline_preds[val_idx])\n",
    "    baseline_fold_accs.append(fold_acc)\n",
    "    print(f\"  Fold {fold}: accuracy={fold_acc:.4f} (n={len(val_idx)})\")\n",
    "\n",
    "print(f\"\\nBaseline overall accuracy: {baseline_acc:.4f}\")\n",
    "print(f\"Per-fold mean: {np.mean(baseline_fold_accs):.4f} +/- {np.std(baseline_fold_accs):.4f}\")\n",
    "print()\n",
    "print(classification_report(y_baseline, baseline_preds, target_names=[\"correct\", \"incorrect\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: 3D CNN (R3D-18)\n",
    "\n",
    "Pretrained on Kinetics-400, frozen backbone, fine-tune FC layer only (1,026 trainable params)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_DIR = Path(\"../data/raw/kaggle_pushups\")\n",
    "\n",
    "def make_r3d_model():\n",
    "    return PushUpVideoClassifier(freeze_backbone=True, num_classes=2)\n",
    "\n",
    "def make_video_dataset(ids):\n",
    "    return PushUpVideoDataset(\n",
    "        manifest=manifest,\n",
    "        video_dir=VIDEO_DIR,\n",
    "        video_ids=ids,\n",
    "        n_frames=16,\n",
    "    )\n",
    "\n",
    "print(\"Training R3D-18 with 5-fold stratified CV...\")\n",
    "print(f\"  Trainable params: {sum(p.numel() for p in make_r3d_model().parameters() if p.requires_grad)}\")\n",
    "\n",
    "r3d_results = run_kfold_cv(\n",
    "    model_factory=make_r3d_model,\n",
    "    dataset_factory=make_video_dataset,\n",
    "    video_ids=video_ids,\n",
    "    labels=labels,\n",
    "    n_splits=N_SPLITS,\n",
    "    n_epochs=30,\n",
    "    batch_size=8,\n",
    "    lr=1e-3,\n",
    "    patience=10,\n",
    "    device_str=device_str,\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "r3d_fold_accs = [f[\"val_accuracy\"] for f in r3d_results[\"fold_results\"]]\n",
    "print(f\"\\nR3D-18 per-fold accuracies: {[f'{a:.4f}' for a in r3d_fold_accs]}\")\n",
    "print(f\"Mean: {np.mean(r3d_fold_accs):.4f} +/- {np.std(r3d_fold_accs):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: ST-GCN\n",
    "\n",
    "Spatial-Temporal Graph Convolutional Network on torso-normalized skeleton sequences (~245K params)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEYPOINT_DIR = Path(\"../data/processed/keypoints/yolo\")\n",
    "\n",
    "def make_stgcn_model():\n",
    "    return PushUpSTGCN(in_channels=2, num_classes=2, dropout=0.2)\n",
    "\n",
    "def make_skeleton_dataset(ids):\n",
    "    return PushUpSkeletonDataset(\n",
    "        manifest=manifest,\n",
    "        keypoint_dir=KEYPOINT_DIR,\n",
    "        video_ids=ids,\n",
    "        max_frames=150,\n",
    "        normalize=True,\n",
    "    )\n",
    "\n",
    "print(\"Training ST-GCN with 5-fold stratified CV...\")\n",
    "n_params = sum(p.numel() for p in make_stgcn_model().parameters() if p.requires_grad)\n",
    "print(f\"  Trainable params: {n_params:,}\")\n",
    "\n",
    "stgcn_results = run_kfold_cv(\n",
    "    model_factory=make_stgcn_model,\n",
    "    dataset_factory=make_skeleton_dataset,\n",
    "    video_ids=video_ids,\n",
    "    labels=labels,\n",
    "    n_splits=N_SPLITS,\n",
    "    n_epochs=50,\n",
    "    batch_size=8,\n",
    "    lr=1e-3,\n",
    "    patience=15,\n",
    "    device_str=device_str,\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "stgcn_fold_accs = [f[\"val_accuracy\"] for f in stgcn_results[\"fold_results\"]]\n",
    "print(f\"\\nST-GCN per-fold accuracies: {[f'{a:.4f}' for a in stgcn_fold_accs]}\")\n",
    "print(f\"Mean: {np.mean(stgcn_fold_accs):.4f} +/- {np.std(stgcn_fold_accs):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Comparison\n",
    "\n",
    "Per-fold accuracy table and bar chart with error bars across all three methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-fold accuracy table\n",
    "comparison_data = {\n",
    "    \"Fold\": list(range(N_SPLITS)),\n",
    "    \"Baseline (LR)\": baseline_fold_accs,\n",
    "    \"R3D-18\": r3d_fold_accs,\n",
    "    \"ST-GCN\": stgcn_fold_accs,\n",
    "}\n",
    "df_comparison = pd.DataFrame(comparison_data)\n",
    "\n",
    "# Add mean row\n",
    "mean_row = pd.DataFrame([{\n",
    "    \"Fold\": \"Mean\",\n",
    "    \"Baseline (LR)\": np.mean(baseline_fold_accs),\n",
    "    \"R3D-18\": np.mean(r3d_fold_accs),\n",
    "    \"ST-GCN\": np.mean(stgcn_fold_accs),\n",
    "}])\n",
    "df_display = pd.concat([df_comparison, mean_row], ignore_index=True)\n",
    "print(df_display.to_string(index=False))\n",
    "\n",
    "# Bar chart with error bars\n",
    "methods = [\"Baseline (LR)\", \"R3D-18\", \"ST-GCN\"]\n",
    "means = [np.mean(baseline_fold_accs), np.mean(r3d_fold_accs), np.mean(stgcn_fold_accs)]\n",
    "stds = [np.std(baseline_fold_accs), np.std(r3d_fold_accs), np.std(stgcn_fold_accs)]\n",
    "colors = [\"#4C72B0\", \"#DD8452\", \"#55A868\"]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "bars = ax.bar(methods, means, yerr=stds, capsize=8, color=colors, alpha=0.85, edgecolor=\"black\")\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, mean, std in zip(bars, means, stds):\n",
    "    ax.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + std + 0.01,\n",
    "            f\"{mean:.1%}\", ha=\"center\", va=\"bottom\", fontweight=\"bold\")\n",
    "\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.set_title(\"Form Classification: 5-Fold CV Accuracy Comparison\")\n",
    "ax.set_ylim(0, 1.15)\n",
    "ax.axhline(0.5, color=\"gray\", linestyle=\"--\", alpha=0.5, label=\"Chance\")\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../outputs/figures/06_accuracy_comparison.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrices side-by-side\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 4.5))\n",
    "class_names = [\"correct\", \"incorrect\"]\n",
    "\n",
    "# Baseline\n",
    "cm_baseline = confusion_matrix(y_baseline, baseline_preds)\n",
    "sns.heatmap(cm_baseline, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=class_names, yticklabels=class_names, ax=axes[0])\n",
    "axes[0].set_title(f\"Baseline (LR) — {baseline_acc:.1%}\")\n",
    "axes[0].set_xlabel(\"Predicted\")\n",
    "axes[0].set_ylabel(\"True\")\n",
    "\n",
    "# R3D-18\n",
    "r3d_true = [r3d_results[\"per_video_true\"][v] for v in video_ids]\n",
    "r3d_pred = [r3d_results[\"per_video_preds\"][v] for v in video_ids]\n",
    "cm_r3d = confusion_matrix(r3d_true, r3d_pred)\n",
    "r3d_acc = accuracy_score(r3d_true, r3d_pred)\n",
    "sns.heatmap(cm_r3d, annot=True, fmt=\"d\", cmap=\"Oranges\",\n",
    "            xticklabels=class_names, yticklabels=class_names, ax=axes[1])\n",
    "axes[1].set_title(f\"R3D-18 — {r3d_acc:.1%}\")\n",
    "axes[1].set_xlabel(\"Predicted\")\n",
    "axes[1].set_ylabel(\"True\")\n",
    "\n",
    "# ST-GCN\n",
    "stgcn_true = [stgcn_results[\"per_video_true\"][v] for v in video_ids]\n",
    "stgcn_pred = [stgcn_results[\"per_video_preds\"][v] for v in video_ids]\n",
    "cm_stgcn = confusion_matrix(stgcn_true, stgcn_pred)\n",
    "stgcn_acc = accuracy_score(stgcn_true, stgcn_pred)\n",
    "sns.heatmap(cm_stgcn, annot=True, fmt=\"d\", cmap=\"Greens\",\n",
    "            xticklabels=class_names, yticklabels=class_names, ax=axes[2])\n",
    "axes[2].set_title(f\"ST-GCN — {stgcn_acc:.1%}\")\n",
    "axes[2].set_xlabel(\"Predicted\")\n",
    "axes[2].set_ylabel(\"True\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../outputs/figures/06_confusion_matrices.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Error Analysis\n",
    "\n",
    "Per-video predictions — identify hard videos and cross-reference with angle statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-video prediction summary\n",
    "results_rows = []\n",
    "for vid_id in video_ids:\n",
    "    true_label = 0 if manifest[vid_id][\"label\"] == \"correct\" else 1\n",
    "    row = {\n",
    "        \"video_id\": vid_id,\n",
    "        \"true_label\": manifest[vid_id][\"label\"],\n",
    "        \"baseline_pred\": \"correct\" if baseline_preds[video_ids.index(vid_id)] == 0 else \"incorrect\",\n",
    "        \"r3d_pred\": \"correct\" if r3d_results[\"per_video_preds\"][vid_id] == 0 else \"incorrect\",\n",
    "        \"stgcn_pred\": \"correct\" if stgcn_results[\"per_video_preds\"][vid_id] == 0 else \"incorrect\",\n",
    "    }\n",
    "    row[\"baseline_correct\"] = row[\"baseline_pred\"] == row[\"true_label\"]\n",
    "    row[\"r3d_correct\"] = row[\"r3d_pred\"] == row[\"true_label\"]\n",
    "    row[\"stgcn_correct\"] = row[\"stgcn_pred\"] == row[\"true_label\"]\n",
    "    row[\"n_correct_models\"] = sum([row[\"baseline_correct\"], row[\"r3d_correct\"], row[\"stgcn_correct\"]])\n",
    "    results_rows.append(row)\n",
    "\n",
    "df_results = pd.DataFrame(results_rows)\n",
    "\n",
    "# Hard videos: misclassified by at least 2 methods\n",
    "hard_videos = df_results[df_results[\"n_correct_models\"] <= 1]\n",
    "print(f\"Hard videos (misclassified by >= 2 methods): {len(hard_videos)}\")\n",
    "if len(hard_videos) > 0:\n",
    "    print(hard_videos[[\"video_id\", \"true_label\", \"baseline_pred\", \"r3d_pred\", \"stgcn_pred\"]].to_string(index=False))\n",
    "\n",
    "# Cross-reference with angle stats for hard videos\n",
    "if len(hard_videos) > 0:\n",
    "    print(\"\\nAngle statistics for hard videos:\")\n",
    "    hard_ids = hard_videos[\"video_id\"].tolist()\n",
    "    hard_feats = feat_df.loc[hard_ids, [\"elbow_mean\", \"elbow_min\", \"back_mean\", \"hip_mean\"]]\n",
    "    print(hard_feats.to_string())\n",
    "\n",
    "    # Duration info\n",
    "    print(\"\\nDuration info:\")\n",
    "    for vid_id in hard_ids:\n",
    "        dur = manifest[vid_id].get(\"duration_s\", \"?\")\n",
    "        n_frames = manifest[vid_id].get(\"n_frames\", \"?\")\n",
    "        print(f\"  {vid_id}: {dur}s, {n_frames} frames\")\n",
    "\n",
    "# Agreement analysis\n",
    "all_agree = (df_results[\"n_correct_models\"] == 3).sum()\n",
    "two_agree = (df_results[\"n_correct_models\"] >= 2).sum()\n",
    "print(f\"\\nAll 3 methods correct: {all_agree}/{len(video_ids)} ({all_agree/len(video_ids):.1%})\")\n",
    "print(f\"Majority (>= 2) correct: {two_agree}/{len(video_ids)} ({two_agree/len(video_ids):.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6: Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "RESULTS_DIR = Path(\"../outputs/results\")\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "FIGURES_DIR = Path(\"../outputs/figures\")\n",
    "FIGURES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MODEL_DIR = Path(\"../models\")\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save per-video results\n",
    "df_results.to_csv(RESULTS_DIR / \"form_classification_results.csv\", index=False)\n",
    "print(f\"Saved: {RESULTS_DIR / 'form_classification_results.csv'} ({len(df_results)} rows)\")\n",
    "\n",
    "# Save comparison summary\n",
    "summary = pd.DataFrame({\n",
    "    \"Method\": methods,\n",
    "    \"Mean_Accuracy\": means,\n",
    "    \"Std_Accuracy\": stds,\n",
    "    \"Per_Fold\": [baseline_fold_accs, r3d_fold_accs, stgcn_fold_accs],\n",
    "})\n",
    "summary.to_csv(RESULTS_DIR / \"form_classification_summary.csv\", index=False)\n",
    "print(f\"Saved: {RESULTS_DIR / 'form_classification_summary.csv'}\")\n",
    "\n",
    "# Save best ST-GCN model\n",
    "if stgcn_results[\"best_state\"] is not None:\n",
    "    torch.save(stgcn_results[\"best_state\"], MODEL_DIR / \"stgcn_best.pt\")\n",
    "    print(f\"Saved best ST-GCN model: {MODEL_DIR / 'stgcn_best.pt'}\")\n",
    "\n",
    "print(\"\\n=== Summary ===\")\n",
    "for method, acc, std in zip(methods, means, stds):\n",
    "    print(f\"  {method:15s}: {acc:.1%} +/- {std:.1%}\")\n",
    "print(f\"\\nFigures saved to: {FIGURES_DIR}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Push-Up Tracker (Python 3.12)",
   "language": "python",
   "name": "pushup-tracker"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
