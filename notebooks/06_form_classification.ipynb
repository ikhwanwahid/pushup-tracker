{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06 — Per-Rep Form Classification: Baseline vs 3D CNN vs ST-GCN\n",
    "\n",
    "Binary per-rep form classification (correct vs incorrect) using three approaches:\n",
    "1. **Logistic Regression** baseline on per-rep angle statistics\n",
    "2. **3D CNN (R3D-18)** fine-tuned on rep video clips\n",
    "3. **ST-GCN** on rep skeleton keypoint sequences\n",
    "\n",
    "All evaluated on the same 5-fold stratified cross-validation splits (split by video, not by rep)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "import json\n",
    "import logging\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "from src.classification.stgcn import PushUpSTGCN\n",
    "from src.classification.video_classifier import PushUpVideoClassifier\n",
    "from src.classification.datasets import PushUpRepSkeletonDataset, PushUpRepVideoDataset\n",
    "from src.classification.train_classifier import run_rep_kfold_cv\n",
    "from src.classification.rep_segmenter import segment_all_videos, compute_rep_features\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(levelname)s: %(message)s\")\n",
    "\n",
    "# Load manifest\n",
    "with open(\"../data/processed/keypoints/manifest.json\") as f:\n",
    "    manifest = json.load(f)\n",
    "\n",
    "# Paths\n",
    "KEYPOINT_DIR = Path(\"../data/processed/keypoints/yolo\")\n",
    "VIDEO_DIR = Path(\"../data/raw/kaggle_pushups\")\n",
    "\n",
    "# Device selection\n",
    "if torch.cuda.is_available():\n",
    "    device_str = \"cuda\"\n",
    "elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "    device_str = \"mps\"\n",
    "else:\n",
    "    device_str = \"cpu\"\n",
    "print(f\"Using device: {device_str}\")\n",
    "\n",
    "# Segment all videos into individual reps\n",
    "rep_segments = segment_all_videos(manifest, KEYPOINT_DIR)\n",
    "\n",
    "# Add video_path for the video dataset\n",
    "for rep in rep_segments:\n",
    "    rep[\"video_path\"] = str(VIDEO_DIR / manifest[rep[\"video_id\"]][\"original_path\"])\n",
    "\n",
    "# Stats\n",
    "n_correct = sum(1 for r in rep_segments if r[\"label\"] == 0)\n",
    "n_incorrect = sum(1 for r in rep_segments if r[\"label\"] == 1)\n",
    "rep_lengths = [r[\"end_frame\"] - r[\"start_frame\"] + 1 for r in rep_segments]\n",
    "\n",
    "print(f\"Total reps: {len(rep_segments)}\")\n",
    "print(f\"  Correct: {n_correct}, Incorrect: {n_incorrect}\")\n",
    "print(f\"  Rep length: min={min(rep_lengths)}, max={max(rep_lengths)}, median={np.median(rep_lengths):.0f}\")\n",
    "\n",
    "# Common CV config\n",
    "RANDOM_STATE = 42\n",
    "N_SPLITS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Baseline — Logistic Regression\n",
    "\n",
    "Uses 16 per-rep angle statistics (mean/min/max/range for elbow, back, hip, knee angles)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute per-rep features\n",
    "X_baseline = np.stack([compute_rep_features(r[\"keypoints\"]) for r in rep_segments])\n",
    "y_baseline = np.array([r[\"label\"] for r in rep_segments])\n",
    "rep_video_ids = np.array([r[\"video_id\"] for r in rep_segments])\n",
    "\n",
    "print(f\"Feature matrix: {X_baseline.shape}\")\n",
    "\n",
    "# Get unique videos for stratified splitting\n",
    "unique_vids = []\n",
    "unique_labels = []\n",
    "seen = set()\n",
    "for r in rep_segments:\n",
    "    if r[\"video_id\"] not in seen:\n",
    "        unique_vids.append(r[\"video_id\"])\n",
    "        unique_labels.append(r[\"label\"])\n",
    "        seen.add(r[\"video_id\"])\n",
    "unique_vids = np.array(unique_vids)\n",
    "unique_labels = np.array(unique_labels)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "# Cross-validated predictions, split by video\n",
    "baseline_preds = np.full(len(rep_segments), -1)\n",
    "baseline_fold_accs = []\n",
    "\n",
    "for fold, (train_vid_idx, val_vid_idx) in enumerate(skf.split(unique_vids, unique_labels)):\n",
    "    train_vid_set = set(unique_vids[train_vid_idx])\n",
    "    val_vid_set = set(unique_vids[val_vid_idx])\n",
    "\n",
    "    train_mask = np.array([v in train_vid_set for v in rep_video_ids])\n",
    "    val_mask = np.array([v in val_vid_set for v in rep_video_ids])\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"lr\", LogisticRegression(max_iter=1000, random_state=RANDOM_STATE)),\n",
    "    ])\n",
    "    pipeline.fit(X_baseline[train_mask], y_baseline[train_mask])\n",
    "    preds = pipeline.predict(X_baseline[val_mask])\n",
    "    baseline_preds[val_mask] = preds\n",
    "\n",
    "    fold_acc = accuracy_score(y_baseline[val_mask], preds)\n",
    "    baseline_fold_accs.append(fold_acc)\n",
    "    print(f\"  Fold {fold}: accuracy={fold_acc:.4f} (n_reps={val_mask.sum()})\")\n",
    "\n",
    "baseline_acc = accuracy_score(y_baseline, baseline_preds)\n",
    "print(f\"\\nBaseline overall accuracy: {baseline_acc:.4f}\")\n",
    "print(f\"Per-fold mean: {np.mean(baseline_fold_accs):.4f} +/- {np.std(baseline_fold_accs):.4f}\")\n",
    "print()\n",
    "print(classification_report(y_baseline, baseline_preds, target_names=[\"correct\", \"incorrect\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: 3D CNN (R3D-18)\n",
    "\n",
    "Pretrained on Kinetics-400, frozen backbone, fine-tune FC layer only (1,026 trainable params). Classifies per-rep video clips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_r3d_model():\n",
    "    return PushUpVideoClassifier(freeze_backbone=True, num_classes=2)\n",
    "\n",
    "def make_rep_video_dataset(reps):\n",
    "    return PushUpRepVideoDataset(reps, n_frames=16)\n",
    "\n",
    "print(\"Training R3D-18 with 5-fold stratified CV (split by video)...\")\n",
    "print(f\"  Trainable params: {sum(p.numel() for p in make_r3d_model().parameters() if p.requires_grad)}\")\n",
    "\n",
    "r3d_results = run_rep_kfold_cv(\n",
    "    model_factory=make_r3d_model,\n",
    "    dataset_factory=make_rep_video_dataset,\n",
    "    rep_segments=rep_segments,\n",
    "    n_splits=N_SPLITS,\n",
    "    n_epochs=30,\n",
    "    batch_size=8,\n",
    "    lr=1e-3,\n",
    "    patience=10,\n",
    "    device_str=device_str,\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "r3d_fold_accs = [f[\"val_accuracy\"] for f in r3d_results[\"fold_results\"]]\n",
    "print(f\"\\nR3D-18 per-fold accuracies: {[f'{a:.4f}' for a in r3d_fold_accs]}\")\n",
    "print(f\"Mean: {np.mean(r3d_fold_accs):.4f} +/- {np.std(r3d_fold_accs):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: ST-GCN\n",
    "\n",
    "Spatial-Temporal Graph Convolutional Network on torso-normalized per-rep skeleton sequences (~245K params)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_stgcn_model():\n",
    "    return PushUpSTGCN(in_channels=2, num_classes=2, dropout=0.2)\n",
    "\n",
    "def make_rep_skeleton_dataset(reps):\n",
    "    return PushUpRepSkeletonDataset(reps, max_frames=64, normalize=True)\n",
    "\n",
    "print(\"Training ST-GCN with 5-fold stratified CV (split by video)...\")\n",
    "n_params = sum(p.numel() for p in make_stgcn_model().parameters() if p.requires_grad)\n",
    "print(f\"  Trainable params: {n_params:,}\")\n",
    "\n",
    "stgcn_results = run_rep_kfold_cv(\n",
    "    model_factory=make_stgcn_model,\n",
    "    dataset_factory=make_rep_skeleton_dataset,\n",
    "    rep_segments=rep_segments,\n",
    "    n_splits=N_SPLITS,\n",
    "    n_epochs=50,\n",
    "    batch_size=16,\n",
    "    lr=1e-3,\n",
    "    patience=15,\n",
    "    device_str=device_str,\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "stgcn_fold_accs = [f[\"val_accuracy\"] for f in stgcn_results[\"fold_results\"]]\n",
    "print(f\"\\nST-GCN per-fold accuracies: {[f'{a:.4f}' for a in stgcn_fold_accs]}\")\n",
    "print(f\"Mean: {np.mean(stgcn_fold_accs):.4f} +/- {np.std(stgcn_fold_accs):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Comparison\n",
    "\n",
    "Per-fold accuracy table and bar chart with error bars across all three methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-fold accuracy table\n",
    "methods = [\"Baseline (LR)\", \"R3D-18\", \"ST-GCN\"]\n",
    "all_fold_accs = [baseline_fold_accs, r3d_fold_accs, stgcn_fold_accs]\n",
    "means = [np.mean(a) for a in all_fold_accs]\n",
    "stds = [np.std(a) for a in all_fold_accs]\n",
    "\n",
    "comparison_data = {\"Fold\": list(range(N_SPLITS))}\n",
    "for name, accs in zip(methods, all_fold_accs):\n",
    "    comparison_data[name] = accs\n",
    "df_comparison = pd.DataFrame(comparison_data)\n",
    "\n",
    "mean_row = pd.DataFrame([{\n",
    "    \"Fold\": \"Mean\",\n",
    "    **{name: np.mean(accs) for name, accs in zip(methods, all_fold_accs)}\n",
    "}])\n",
    "print(pd.concat([df_comparison, mean_row], ignore_index=True).to_string(index=False))\n",
    "\n",
    "# Bar chart with error bars\n",
    "colors = [\"#4C72B0\", \"#DD8452\", \"#55A868\"]\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "bars = ax.bar(methods, means, yerr=stds, capsize=8, color=colors, alpha=0.85, edgecolor=\"black\")\n",
    "\n",
    "for bar, mean, std in zip(bars, means, stds):\n",
    "    ax.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + std + 0.01,\n",
    "            f\"{mean:.1%}\", ha=\"center\", va=\"bottom\", fontweight=\"bold\")\n",
    "\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.set_title(f\"Per-Rep Form Classification: 5-Fold CV ({len(rep_segments)} reps)\")\n",
    "ax.set_ylim(0, 1.15)\n",
    "ax.axhline(0.5, color=\"gray\", linestyle=\"--\", alpha=0.5, label=\"Chance\")\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../outputs/figures/06_accuracy_comparison.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrices side-by-side\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 4.5))\n",
    "class_names = [\"correct\", \"incorrect\"]\n",
    "\n",
    "# Baseline\n",
    "cm_baseline = confusion_matrix(y_baseline, baseline_preds)\n",
    "sns.heatmap(cm_baseline, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=class_names, yticklabels=class_names, ax=axes[0])\n",
    "axes[0].set_title(f\"Baseline (LR) — {baseline_acc:.1%}\")\n",
    "axes[0].set_xlabel(\"Predicted\")\n",
    "axes[0].set_ylabel(\"True\")\n",
    "\n",
    "# R3D-18\n",
    "r3d_true = r3d_results[\"per_rep_true\"]\n",
    "r3d_pred = r3d_results[\"per_rep_preds\"]\n",
    "cm_r3d = confusion_matrix(r3d_true, r3d_pred)\n",
    "r3d_acc = accuracy_score(r3d_true, r3d_pred)\n",
    "sns.heatmap(cm_r3d, annot=True, fmt=\"d\", cmap=\"Oranges\",\n",
    "            xticklabels=class_names, yticklabels=class_names, ax=axes[1])\n",
    "axes[1].set_title(f\"R3D-18 — {r3d_acc:.1%}\")\n",
    "axes[1].set_xlabel(\"Predicted\")\n",
    "axes[1].set_ylabel(\"True\")\n",
    "\n",
    "# ST-GCN\n",
    "stgcn_true = stgcn_results[\"per_rep_true\"]\n",
    "stgcn_pred = stgcn_results[\"per_rep_preds\"]\n",
    "cm_stgcn = confusion_matrix(stgcn_true, stgcn_pred)\n",
    "stgcn_acc = accuracy_score(stgcn_true, stgcn_pred)\n",
    "sns.heatmap(cm_stgcn, annot=True, fmt=\"d\", cmap=\"Greens\",\n",
    "            xticklabels=class_names, yticklabels=class_names, ax=axes[2])\n",
    "axes[2].set_title(f\"ST-GCN — {stgcn_acc:.1%}\")\n",
    "axes[2].set_xlabel(\"Predicted\")\n",
    "axes[2].set_ylabel(\"True\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../outputs/figures/06_confusion_matrices.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Error Analysis\n",
    "\n",
    "Per-rep predictions — identify hard reps and cross-reference with source videos and angle statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-rep prediction summary\n",
    "results_rows = []\n",
    "for i, rep in enumerate(rep_segments):\n",
    "    row = {\n",
    "        \"video_id\": rep[\"video_id\"],\n",
    "        \"rep_idx\": rep[\"rep_idx\"],\n",
    "        \"true_label\": \"correct\" if rep[\"label\"] == 0 else \"incorrect\",\n",
    "        \"n_frames\": rep[\"end_frame\"] - rep[\"start_frame\"] + 1,\n",
    "        \"baseline_pred\": \"correct\" if baseline_preds[i] == 0 else \"incorrect\",\n",
    "        \"r3d_pred\": \"correct\" if r3d_pred[i] == 0 else \"incorrect\",\n",
    "        \"stgcn_pred\": \"correct\" if stgcn_pred[i] == 0 else \"incorrect\",\n",
    "    }\n",
    "    row[\"baseline_correct\"] = row[\"baseline_pred\"] == row[\"true_label\"]\n",
    "    row[\"r3d_correct\"] = row[\"r3d_pred\"] == row[\"true_label\"]\n",
    "    row[\"stgcn_correct\"] = row[\"stgcn_pred\"] == row[\"true_label\"]\n",
    "    row[\"n_correct_models\"] = sum([row[\"baseline_correct\"], row[\"r3d_correct\"], row[\"stgcn_correct\"]])\n",
    "    results_rows.append(row)\n",
    "\n",
    "df_results = pd.DataFrame(results_rows)\n",
    "\n",
    "# Hard reps: misclassified by >= 2 methods\n",
    "hard_reps = df_results[df_results[\"n_correct_models\"] <= 1]\n",
    "print(f\"Hard reps (misclassified by >= 2 methods): {len(hard_reps)} / {len(rep_segments)}\")\n",
    "if len(hard_reps) > 0:\n",
    "    print(hard_reps[[\"video_id\", \"rep_idx\", \"true_label\", \"n_frames\",\n",
    "                      \"baseline_pred\", \"r3d_pred\", \"stgcn_pred\"]].to_string(index=False))\n",
    "\n",
    "# Per-video agreement\n",
    "video_summary = df_results.groupby(\"video_id\").agg(\n",
    "    n_reps=(\"rep_idx\", \"count\"),\n",
    "    baseline_acc=(\"baseline_correct\", \"mean\"),\n",
    "    r3d_acc=(\"r3d_correct\", \"mean\"),\n",
    "    stgcn_acc=(\"stgcn_correct\", \"mean\"),\n",
    ").reset_index()\n",
    "\n",
    "print(f\"\\nPer-video stats: {len(video_summary)} videos with reps\")\n",
    "print(f\"  Mean reps/video: {video_summary['n_reps'].mean():.1f}\")\n",
    "\n",
    "# All 3 methods correct\n",
    "all_agree = (df_results[\"n_correct_models\"] == 3).sum()\n",
    "two_agree = (df_results[\"n_correct_models\"] >= 2).sum()\n",
    "print(f\"\\nAll 3 methods correct: {all_agree}/{len(rep_segments)} ({all_agree/len(rep_segments):.1%})\")\n",
    "print(f\"Majority (>= 2) correct: {two_agree}/{len(rep_segments)} ({two_agree/len(rep_segments):.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6: Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "RESULTS_DIR = Path(\"../outputs/results\")\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FIGURES_DIR = Path(\"../outputs/figures\")\n",
    "FIGURES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "MODEL_DIR = Path(\"../models\")\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save per-rep results\n",
    "df_results.to_csv(RESULTS_DIR / \"form_classification_results.csv\", index=False)\n",
    "print(f\"Saved: {RESULTS_DIR / 'form_classification_results.csv'} ({len(df_results)} reps)\")\n",
    "\n",
    "# Save comparison summary\n",
    "summary = pd.DataFrame({\n",
    "    \"Method\": methods,\n",
    "    \"Mean_Accuracy\": means,\n",
    "    \"Std_Accuracy\": stds,\n",
    "    \"Per_Fold\": [str(a) for a in all_fold_accs],\n",
    "})\n",
    "summary.to_csv(RESULTS_DIR / \"form_classification_summary.csv\", index=False)\n",
    "print(f\"Saved: {RESULTS_DIR / 'form_classification_summary.csv'}\")\n",
    "\n",
    "# Save best ST-GCN model\n",
    "if stgcn_results[\"best_state\"] is not None:\n",
    "    torch.save(stgcn_results[\"best_state\"], MODEL_DIR / \"stgcn_best.pt\")\n",
    "    print(f\"Saved best ST-GCN model: {MODEL_DIR / 'stgcn_best.pt'}\")\n",
    "\n",
    "print(f\"\\n=== Summary ({len(rep_segments)} reps from {len(video_summary)} videos) ===\")\n",
    "for method, acc, std in zip(methods, means, stds):\n",
    "    print(f\"  {method:15s}: {acc:.1%} +/- {std:.1%}\")\n",
    "print(f\"\\nFigures saved to: {FIGURES_DIR}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Push-Up Tracker (Python 3.12)",
   "language": "python",
   "name": "pushup-tracker"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
